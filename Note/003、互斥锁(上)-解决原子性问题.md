### 回顾

```java
什么是原子性？
	一个或者多个操作在CPU执行的过程中不被中断的特性，称为“原子性”。
```

#### 原子性问题到底该如何解决呢？

```java
原子性问题的源头是"线程切换"。
操作系统做线程切换是依赖CPU中断的，所以禁止CPU发生中断就能够禁止线程切换。
    在早期单核CPU时代，这个方案的确是可行的。
    以32位CPU上执行long型变量的写操作为例来说明这个问题，long型变量是64位，在32位CPU上执行写操作会被拆分成两次写操作（写高32位和写低32位，如下图所示）。
```

![002_concurrent](G:\DevCache\Cache\concurrent-parent\Note\pic\002_concurrent.png)

```java
	在单核CPU场景下，同一时刻只有一个线程执行，禁止CPU中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得CPU使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。
    但是在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程执行在CPU-1上，一个线程执行在CPU-2上，此时禁止CPU中断，只能保证CPU上的线程连续执行，并不能保证同一时刻只有一个线程执行。
	"同一时刻只有一个线程执行"这个条件非常重要，我们称之为互斥。如果我们能够保证对共享变量的修改是互斥的，那么，无论是单核还是多核CPU，就都能保证原子性了。
```

#### 正确理解锁模型

```java
	在现实世界里，锁和锁要保护的资源是有对应关系的，比如你用你家的锁保护你家的东西，我用我家的锁保护我家的东西。
	在并发编程世界里，锁和资源也应该有这个关系。下面是改进后的锁模型。
```

![003_concurrent](G:\DevCache\Cache\concurrent-parent\Note\pic\003_concurrent.png)

```java
首先：我们要把临界区要保护的资源标注出来，如图中临界区里增加了一个元素：受保护的资源R；
其次：我们要保护资源R就得为它创建一把锁LR；
最后：针对这把锁LR，我们还需在进出临界区时添上加锁操作和解锁操作。
另外：在锁LR和受保护资源之间，我特地用一条线做了关联，这个关联关系非常重要。表示用自家锁保护自家资产。
```

##### Java语言提供的锁技术：synchronized

```java
锁是一种通用的技术方案，Java语言提供的synchronized关键字，就是锁的一种实现。
synchronized关键字可以用来修饰方法，也可以用来修饰代码块，它的使用示例基本上都是下面这个样子：
public class X {
    // 修饰非静态方法
    synchronized void foo() {
        // 临界区
    }
    // 修饰静态方法
    synchronized static void bar() {
        // 临界区
    }
    // 修饰代码块
    Object obj = new Object();
    void baz() {
        synchronized(obj) {
            // 临界区
        }
    }
}  

synchronized的加锁lock()和解锁unlock()在哪里呢？
    Java编译器会在synchronized修饰的方法或代码块前后自动加上加锁lock()和解锁unlock()，这样做的好处就是加锁lock()和解锁unlock()一定是成对出现的。

那synchronized里的加锁lock()和解锁unlock()锁定的对象在哪里呢？上面的代码我们看到只有修饰代码块的时候，锁定了一个obj对象，那修饰方法的时候锁定的是什么呢？
    这个也是Java的一条隐式规则：
    	当修饰静态方法的时候，锁定的是当前类的Class对象，在上面的例子中就是Class X；
    	当修饰非静态方法的时候，锁定的是当前实例对象this。

对于上面的例子，synchronized修饰静态方法相当于:
class X {
  // 修饰静态方法
  synchronized(X.class) static void bar() {
    // 临界区
  }
}

修饰非静态方法，相当于：
class X {
  // 修饰非静态方法
  synchronized(this) void foo() {
    // 临界区
  }
}
```

##### 用synchronized解决count+=1问题

```java
class SafeCalc {
  long value = 0L;
  long get() {
    return value;
  }
  synchronized void addOne() {
    value += 1;
  }
}

首先可以肯定，被synchronized修饰后，无论是单核CPU还是多核CPU，只有一个线程能够执行addOne()方法，所以一定能保证原子操作，那是否有可见性问题呢？
    我们知道synchronized修饰的临界区是互斥的，也就是说同一时刻只有一个线程执行临界区的代码；而所谓“对一个锁解锁 Happens-Before 后续对这个锁的加锁”，指的是前一个线程的解锁操作对后一个线程的加锁操作可见，综合Happens-Before的传递性原则，我们就能得出前一个线程在临界区修改的共享变量（该操作在解锁之前），对后续进入临界区（该操作在加锁之后）的线程是可见的。
    
执行addOne()方法后，value的值对get()方法是可见的吗？
    这个可见性是没法保证的。管程中锁的规则，是只保证后续对这个锁的加锁的可见性，而get()方法并没有加锁操作，所以可见性没法保证。
    
那如何解决呢？
    很简单，就是get()方法也synchronized一下，完整的代码如下所示。
class SafeCalc {
  long value = 0L;
  synchronized long get() {
    return value;
  }
  synchronized void addOne() {
    value += 1;
  }
}

上面的代码转换为我们提到的锁模型，就是下面图示这个样子。get()方法和addOne()方法都需要访问value这个受保护的资源，这个资源用this这把锁来保护。线程要进入临界区get()和addOne()，必须先获得this这把锁，这样get()和addOne()也是互斥的。
```

![004_concurrent](G:\DevCache\Cache\concurrent-parent\Note\pic\004_concurrent.png)

#### 锁和受保护资源的关系

```
受保护资源和锁之间的关联关系非常重要，他们的关系是怎样的呢？
	一个合理的关系是：受保护资源和锁之间的关联关系是N:1的关系。
	还拿前面球赛门票的管理来类比，就是一个座位，我们只能用一张票来保护，如果多发了重复的票，那就要打架了。现实世界里，我们可以用多把锁来保护同一个资源，但在并发领域是不行的，并发领域的锁和现实世界的锁不是完全匹配的。不过倒是可以用同一把锁来保护多个资源，这个对应到现实世界就是我们所谓的“包场”了。
```

